{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script is compatible with google cloud functions API\n",
    "import logging\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "index_name = \"neural\"\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "@functions_framework.http\n",
    "def generate(request):\n",
    "    logger.info(\"Entered the generate function\")\n",
    "\n",
    "    if request.method == \"OPTIONS\":\n",
    "        headers = {\n",
    "            \"Access-Control-Allow-Origin\": \"*\",\n",
    "            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",\n",
    "            \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "            \"Access-Control-Max-Age\": \"3600\",\n",
    "        }\n",
    "        return \"\", 204, headers\n",
    "\n",
    "    request_json = request.get_json(silent=True)\n",
    "    if not request_json or 'query' not in request_json:\n",
    "        logger.warning(\"No 'query' field in the request!\")\n",
    "        return \"No 'query' field in your request!\", 400, {\"Access-Control-Allow-Origin\": \"*\"}\n",
    "    \n",
    "    query = request_json['query']\n",
    "    logger.info(f\"Received query: {query}\")\n",
    "\n",
    "    # Perform a similarity search on the vector store\n",
    "    logger.info(\"Performing similarity search\")\n",
    "    search_results = vectorstore.similarity_search(query, k=1)  # Top 3 similar documents\n",
    "    clean_results = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # Generate a response based on the retrieved documents\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant and you have to provide the answer based only on the context provided: {clean_results}\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    response = llm(\n",
    "        messages=f\"Based on the information in the following documents: {clean_results}, respond to the query: {query}\"\n",
    "    )\n",
    "\n",
    "    response = response.content\n",
    "\n",
    "    headers = {\"Access-Control-Allow-Origin\": \"*\"}  \n",
    "    return {\"response\": response}, 200, headers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
